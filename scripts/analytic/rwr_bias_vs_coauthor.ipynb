{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "\n",
        "import sys\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "# each JSON is small, there's no need in iterative processing\n",
        "import json\n",
        "import sys\n",
        "import os\n",
        "import xml\n",
        "import time\n",
        "\n",
        "import pyspark\n",
        "from pyspark.conf import SparkConf\n",
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, LongType, IntegerType, FloatType, ArrayType\n",
        "import pyspark.sql.functions as sparkf\n",
        "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
        "\n",
        "import copy\n",
        "import uuid\n",
        "\n",
        "spark = (pyspark.sql.SparkSession.builder.getOrCreate())\n",
        "\n",
        "coauthor_dir        = \"gs://clpub/data_lake/arnet/tables/coauthor/merge-0\"\n",
        "author_rwr_dir      = \"gs://clpub/data_lake/arnet/tables/author_rwr_bias/merge-0\"\n",
        "\n",
        "from typing import Iterator, Tuple\n",
        "import pandas as pd\n",
        "\n",
        "coauthor_schema = StructType([\n",
        "    StructField('_id', StringType(), False),\n",
        "    StructField('_status', IntegerType(), False),\n",
        "    StructField('_order', IntegerType(), False),\n",
        "    StructField('paper_id', StringType(), False),\n",
        "    StructField('paper_title', StringType(), False),\n",
        "    StructField('author1_id', StringType(), False),\n",
        "    StructField('author1_name', StringType(), False),\n",
        "    StructField('author1_org', StringType(), False),\n",
        "    StructField('author2_id', StringType(), False),\n",
        "    StructField('author2_name', StringType(), False),\n",
        "    StructField('author2_org', StringType(), False),\n",
        "    StructField('year', FloatType(), False),\n",
        "])\n",
        "coauthor_df = spark.read.schema(coauthor_schema).parquet(coauthor_dir)\n",
        "coauthor_df.createOrReplaceTempView(\"coauthor_df\")\n",
        "coauthor_df.count()\n",
        "\n",
        "author_rwr_schema = StructType([\n",
        "    StructField('author_id', StringType(), False),\n",
        "    StructField('ranking', FloatType(), False),\n",
        "    StructField('computed', IntegerType(), False),\n",
        "])\n",
        "author_rwr_df = spark.read.schema(author_rwr_schema).parquet(author_rwr_dir)\n",
        "author_rwr_df.createOrReplaceTempView(\"author_rwr_df\")\n",
        "\n",
        "group_coauthor = spark.sql(\"\"\"\n",
        "    select author1_id, author2_id, count(_id) as collab\n",
        "    from coauthor_df\n",
        "    group by author1_id, author2_id\n",
        "\"\"\")\n",
        "\n",
        "sample = group_coauthor.sample(0.01, 999).limit(3000).repartition(1).withColumn(\n",
        "    \"datapoint\", sparkf.monotonically_increasing_id())\n",
        "sample.createOrReplaceTempView(\"coauthor_sample\")\n",
        "\n",
        "sample_ranking = spark.sql(\"\"\"\n",
        "    select cs.datapoint, cs.collab, ard1.ranking as author1_ranking, ard2.ranking as author2_ranking\n",
        "    from coauthor_sample as cs\n",
        "        inner join author_rwr_df as ard1 on ard1.author_id = cs.author1_id\n",
        "        inner join author_rwr_df as ard2 on ard2.author_id = cs.author2_id\n",
        "    where ard1.computed = 1 and ard2.computed = 1\n",
        "    order by cs.datapoint\n",
        "    limit 2000\n",
        "\"\"\")\n",
        "\n",
        "from scipy.spatial import distance\n",
        "import numpy as np\n",
        "\n",
        "@pandas_udf(\"float\", PandasUDFType.SCALAR)\n",
        "def node_proximity(v1, v2):\n",
        "    list_r1     =  v1.values.tolist()\n",
        "    list_r2     =  v2.values.tolist() \\\n",
        "    \n",
        "    list_res    = []\n",
        "    for idx in range(0, len(list_r1)):\n",
        "        proximity =  \\\n",
        "            abs(list_r1[idx] - list_r2[idx]) \\\n",
        "            / max(abs(list_r1[idx]), abs(list_r2[idx])) \\\n",
        "\n",
        "        list_res.append(proximity) \\\n",
        "    \n",
        "    return pd.Series(list_res)\n",
        "\n",
        "sample_proximity = sample_ranking.select(sparkf.col(\"datapoint\"), sparkf.col(\"collab\"), \\\n",
        "    node_proximity(sparkf.col(\"author1_ranking\"), sparkf.col(\"author2_ranking\")).alias(\"node_proximity\"))\n",
        "\n",
        "sample_proximity.repartition(1).write.mode(\"overwrite\").csv(\"gs://clpub/diagram/rwr_bias_vs_coauthor\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "\n",
        "df_schema = StructType([\n",
        "    StructField(\"datapoint\", IntegerType(), False),\n",
        "    StructField(\"collab\", LongType(), False),\n",
        "    StructField(\"node_proximity\", FloatType(), False),\n",
        "])\n",
        "\n",
        "df = spark.read.schema(df_schema).csv(\"gs://clpub/diagram/rwr_bias_vs_coauthor\")\n",
        "df.createOrReplaceTempView(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "similar_content_vs_coauthor"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
