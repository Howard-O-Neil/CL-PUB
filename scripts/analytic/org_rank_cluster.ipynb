{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.pyspark\n",
    "\n",
    "import sys\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# each JSON is small, there's no need in iterative processing\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import xml\n",
    "import time\n",
    "\n",
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, IntegerType, FloatType, ArrayType\n",
    "import pyspark.sql.functions as sparkf\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "\n",
    "import copy\n",
    "import uuid\n",
    "\n",
    "spark = (pyspark.sql.SparkSession.builder.getOrCreate())\n",
    "\n",
    "coauthor_dir        = \"gs://clpub/data_lake/arnet/tables/coauthor/merge-0\"\n",
    "author_org_rank_dir = \"gs://clpub/data_lake/arnet/tables/author_org_rank/merge-0\"\n",
    "org_rank_dir        = \"gs://clpub/data_lake/arnet/tables/org_rank_algo/iter-14\"\n",
    "\n",
    "from typing import Iterator, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "org_node_schema = StructType([\n",
    "    StructField(\"_1\", FloatType(), False),\n",
    "    StructField(\"_2\", IntegerType(), False),\n",
    "    StructField(\"_3\", IntegerType(), False),\n",
    "    StructField(\"_4\", LongType(), False),\n",
    "    StructField(\"_5\", FloatType(), False),\n",
    "])\n",
    "org_rank_schema = StructType([\n",
    "    StructField(\"id\", LongType(), False),\n",
    "    StructField(\"node\", org_node_schema, False),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "author_org_ranking_schema = StructType([\n",
    "    StructField('author_id', StringType(), False),\n",
    "    StructField(\"author_org\", StringType(), False),\n",
    "    StructField('org_rank', FloatType(), False),\n",
    "    StructField('computed', IntegerType(), False),\n",
    "])\n",
    "author_org_rank_df = spark.read.schema(author_org_ranking_schema).parquet(author_org_rank_dir)\n",
    "author_org_rank_df.createOrReplaceTempView(\"author_org_ranking_df\")\n",
    "\n",
    "group_coauthor = spark.sql(\"\"\"\n",
    "    select author1_id, author2_id, count(_id) as collab\n",
    "    from coauthor_df\n",
    "    group by author1_id, author2_id\n",
    "\"\"\")\n",
    "\n",
    "sample = group_coauthor.sample(0.01, 999)\n",
    "sample.createOrReplaceTempView(\"coauthor_sample\")\n",
    "\n",
    "sample_ranking = spark.sql(\"\"\"\n",
    "    select cs.collab, aord1.org_rank as author1_ranking, aord2.org_rank as author2_ranking\n",
    "    from coauthor_sample as cs\n",
    "        inner join author_org_ranking_df as aord1 on aord1.author_id = cs.author1_id\n",
    "        inner join author_org_ranking_df as aord2 on aord2.author_id = cs.author2_id\n",
    "    where aord1.computed = 1 and aord2.computed = 1 and aord1.author_org != aord2.author_org\n",
    "        and aord1.author_org != \"\" and aord2.author_org != \"\"\n",
    "    limit 2000\n",
    "\"\"\")\n",
    "\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "@pandas_udf(\"float\", PandasUDFType.SCALAR)\n",
    "def node_proximity(v1, v2):\n",
    "    list_r1     =  v1.values.tolist()\n",
    "    list_r2     =  v2.values.tolist() \\\n",
    "    \n",
    "    list_res    = []\n",
    "    for idx in range(0, len(list_r1)):\n",
    "        proximity = abs(list_r1[idx] - list_r2[idx]) / abs(list_r1[idx] + list_r2[idx])\n",
    "        list_res.append(proximity) \\\n",
    "    \n",
    "    return pd.Series(list_res)\n",
    "\n",
    "sample_proximity = sample_ranking.repartition(1).withColumn(\"datapoint\", sparkf.monotonically_increasing_id()) \\\n",
    "    .select(sparkf.col(\"datapoint\"), sparkf.col(\"collab\"), sparkf.col(\"author1_ranking\"), sparkf.col(\"author2_ranking\"), \\\n",
    "    node_proximity(sparkf.col(\"author1_ranking\"), sparkf.col(\"author2_ranking\")).alias(\"node_proximity\"))\n",
    "\n",
    "sample_proximity.repartition(1).write.mode(\"overwrite\").csv(\"gs://clpub/diagram/org_rank_vs_coauthor_L1_distance\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
