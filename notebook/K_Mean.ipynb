{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24683d8a-d1d3-42bb-8ff3-a90f952607e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/howard/collaborative-recommender/notebook\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_core as tf\n",
    "import numpy as np\n",
    "from BregmanToolkit.bregman import suite as st\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d01a6f7-89da-470f-95e7-d96fca43fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files operation within tensorflow\n",
    "\n",
    "filenames = tf.train.match_filenames_once(\n",
    "    \"/home/howard/collaborative-recommender/data/*.wav\"\n",
    ")\n",
    "count_num_files = tf.size(filenames)\n",
    "filename_queue = tf.train.string_input_producer(filenames)\n",
    "reader = tf.WholeFileReader()\n",
    "filename, file_contents = reader.read(filename_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5394f354-ce96-4f60-bdf0-0791d9399e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init session\n",
    "\n",
    "sess = tf.Session()\n",
    "init = (tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fec97cc4-fcff-4f65-aac0-dfacc01503d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord, sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d806845b-c69f-4cad-8ed1-9b62f9752aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chromagram(sess):\n",
    "    F = st.Chromagram(\n",
    "        sess.run(filename).decode(\"utf-8\"), nfft=16384, wfft=8192, nhop=2205\n",
    "    )\n",
    "    return F.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c22e84b-2963-44d6-a6c1-48750b93d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_vector(sess, chroma_data):\n",
    "    chroma = tf.placeholder(tf.float32)\n",
    "    max_freqs = tf.argmax(chroma, 0)  # first division\n",
    "\n",
    "    num_features, num_samples = np.shape(chroma_data)\n",
    "    freq_vals = sess.run(max_freqs, feed_dict={chroma: chroma_data})\n",
    "    hist, _ = np.histogram(freq_vals, bins=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "    return hist.astype(float) / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9a38ff7-3bc6-4570-ab89-3fcb61d78dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(sess):\n",
    "    num_files = sess.run(count_num_files)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    xs = []\n",
    "    for _ in range(num_files):\n",
    "        chroma_data = get_chromagram(sess)\n",
    "        x = np.matrix(extract_feature_vector(sess, chroma_data))\n",
    "\n",
    "        if len(xs) == 0: xs = x\n",
    "        else: xs = np.vstack((xs, x))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join()\n",
    "\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d9622f8-68ba-41f2-9b2c-11211131cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "max_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "502126a1-2bf4-48d1-a4c1-0c443956ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_centroids(X, k):\n",
    "    # assign centroids label\n",
    "    # 1st centroids -> cluster 0\n",
    "    # 2nd centroids -> cluster 1\n",
    "\n",
    "    return X[0:k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78294563-7247-47e7-8111-41b969b7d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_cluster(X, centroids):\n",
    "    expanded_vectors = tf.expand_dims(X, 0)\n",
    "    expanded_centroids = tf.expand_dims(centroids, 1)\n",
    "    \n",
    "    print(expanded_vectors.get_shape())\n",
    "    print(expanded_centroids.get_shape())\n",
    "\n",
    "    # calculate distance from each vector to each centroids \n",
    "    distances = tf.reduce_sum(tf.square(tf.subtract(expanded_vectors,\n",
    "        expanded_centroids)), 2)\n",
    "\n",
    "    return tf.argmin(distances, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90206e80-c670-4e14-add9-cd9d535190c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recenter_centroids(X, Y, k):\n",
    "    sums = tf.unsorted_segment_sum(X, Y, k)\n",
    "    counts = tf.unsorted_segment_sum(tf.ones_like(X), Y, k)\n",
    "\n",
    "    return sums / counts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be61c28f-0184-4875-80f0-9a2c3701a2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 12)\n",
      "(1, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "(1, 1, 12)\n",
      "(2, 1, 12)\n",
      "[[0.03949447 0.05371248 0.05845182 0.09162717 0.12638231 0.164297\n",
      "  0.164297   0.07740916 0.0300158  0.0600316  0.09794629 0.03633491]\n",
      " [       nan        nan        nan        nan        nan        nan\n",
      "         nan        nan        nan        nan        nan        nan]]\n"
     ]
    }
   ],
   "source": [
    "X = get_dataset(sess)\n",
    "# print(X)\n",
    "centroids = initial_centroids(X, k)\n",
    "\n",
    "i, coveraged = 0, False\n",
    "while not coveraged and i < max_iterations:\n",
    "    i += 1\n",
    "    Y = sess.run(assign_cluster(X, centroids))\n",
    "    centroids = sess.run(recenter_centroids(X, Y, k))\n",
    "\n",
    "print(centroids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
